{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from collections import OrderedDict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoDA_AE(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder_shape, decoder_shape):\n",
    "        super(CoDA_AE, self).__init__()\n",
    "        \n",
    "        #define a list with each element the input and output dim of the layer\n",
    "        layer_list = [[encoder_shape[i], encoder_shape[i+1]] for i in range(0, len(encoder_shape)-1)]\n",
    "        \n",
    "        encoder_dict = OrderedDict()\n",
    "\n",
    "        for i in range(0,len(layer_list)):\n",
    "            encoder_dict[\"layer\"  + str(i)] = nn.Linear(layer_list[i][0], layer_list[i][1])\n",
    "            encoder_dict[\"layer_ac\"  + str(i)] = nn.ELU()\n",
    "\n",
    "\n",
    "        self.encoder = nn.Sequential(encoder_dict)\n",
    "        \n",
    "        layer_list = [[decoder_shape[i], decoder_shape[i+1]] for i in range(0, len(decoder_shape)-1)]\n",
    "        \n",
    "        decoder_dict = OrderedDict()\n",
    "\n",
    "        for i in range(0,len(layer_list)):\n",
    "            decoder_dict[\"layer\"  + str(i)] = nn.Linear(layer_list[i][0], layer_list[i][1])\n",
    "            decoder_dict[\"layer_ac\"  + str(i)] = nn.ELU()\n",
    "\n",
    "        self.decoder = nn.Sequential(decoder_dict)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        #run the encoding and store the low level representation as A\n",
    "        #TODO\n",
    "        #need to create the clr transform of X, then feed both that and X into the encoder\n",
    "        #easier to have encoder_shape as hidden layers, and have the desired dimension and input size as params\n",
    "        \n",
    "        \n",
    "        self.A = self.encoder(x)\n",
    "        self.reconstruction = self.decoder(self.A)\n",
    "        return self.reconstruction\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoDA_AE(\n",
      "  (encoder): Sequential(\n",
      "    (layer0): Linear(in_features=3, out_features=100, bias=True)\n",
      "    (layer_ac0): ELU(alpha=1.0)\n",
      "    (layer1): Linear(in_features=100, out_features=2, bias=True)\n",
      "    (layer_ac1): ELU(alpha=1.0)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (layer0): Linear(in_features=2, out_features=3, bias=True)\n",
      "    (layer_ac0): ELU(alpha=1.0)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "X = features\n",
    "autoencoder = CoDA_AE([3,100,2], [2,3])\n",
    "print (autoencoder)\n",
    "#define the CoDA-PCA loss\n",
    "loss_function = CoDA_Loss()\n",
    "optim = torch.optim.SGD(autoencoder.parameters(), lr = 0.001)\n",
    "    \n",
    "for epoch in range(0,1000):\n",
    "    out = autoencoder.forward(torch.FloatTensor(X))\n",
    "    loss = loss_function(out, torch.FloatTensor(X))\n",
    "        \n",
    "    optim.zero_grad()\n",
    "        \n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "        \n",
    "    epoch += 1\n",
    "    \n",
    "    #print(\"epoch {}, loss {}\".format(epoch, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoDA_Loss(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CoDA_Loss,self).__init__()\n",
    "        \n",
    "    def forward(self,Y,X):\n",
    "        #X is original data, Y is CoDA reconstruction\n",
    "        #input needs to be normalised by g(x) (geometric mean) for X_hat\n",
    "        #TODO centering matrix? Reduce mean? Mask?  \n",
    "        X_check = check(X)\n",
    "        coda_loss = torch.sum(torch.exp(Y)) - torch.sum(X_check * Y)\n",
    "        return coda_loss\n",
    "\n",
    "def check(X):\n",
    "    #assume input is tensor so we can use the numpy() method\n",
    "    assert type(X) == torch.Tensor\n",
    "    gmean = torch.prod(X, 1) ** (1./X.shape[1])\n",
    "    return torch.div(X.t(), gmean).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(267.8988)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = CoDA_Loss()\n",
    "C.forward(torch.FloatTensor([[2,2,2,4], [1,3,3,4], [1,4,3,4]]), torch.FloatTensor([[2,2,3,4], [1,1,1,1], [1,4,3,4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoDA_AE(\n",
      "  (encoder): Sequential(\n",
      "    (layer0): Linear(in_features=3, out_features=100, bias=True)\n",
      "    (layer_ac0): ELU(alpha=1.0)\n",
      "    (layer1): Linear(in_features=100, out_features=2, bias=True)\n",
      "    (layer_ac1): ELU(alpha=1.0)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (layer0): Linear(in_features=2, out_features=3, bias=True)\n",
      "    (layer_ac0): ELU(alpha=1.0)\n",
      "  )\n",
      ")\n",
      "epoch 1000, loss -218.8839111328125\n",
      "epoch 2000, loss -228.36953735351562\n",
      "epoch 3000, loss -232.01467895507812\n",
      "epoch 4000, loss -234.227783203125\n",
      "epoch 5000, loss -239.3748779296875\n",
      "epoch 6000, loss -249.12100219726562\n",
      "epoch 7000, loss -267.6860046386719\n",
      "epoch 8000, loss -271.83929443359375\n",
      "epoch 9000, loss -274.2187194824219\n",
      "epoch 10000, loss -275.87298583984375\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_9 = pd.read_csv(\"Data 9. Urinary excretions (mg_per_24hr) of steroid metabolites for 37 adults and 30 normal children.csv\")\n",
    "adult_inds = np.where(data_9['Adult/Child'] == 'A')\n",
    "child_inds = np.where(data_9['Adult/Child'] == 'C')\n",
    "\n",
    "adult = data_9.to_numpy()[adult_inds]\n",
    "child = data_9.to_numpy()[child_inds]\n",
    "features = data_9[data_9.columns[2:]].to_numpy()\n",
    "\n",
    "\n",
    "features = np.array([feat/sum(feat) for feat in features])\n",
    "\n",
    "\n",
    "\n",
    "X = features\n",
    "autoencoder = CoDA_AE([3,100,2], [2,3])\n",
    "print (autoencoder)\n",
    "#define the CoDA-PCA loss\n",
    "loss_function = CoDA_Loss()\n",
    "optim = torch.optim.SGD(autoencoder.parameters(), lr = 0.001)\n",
    "    \n",
    "for epoch in range(0,10000):\n",
    "    out = autoencoder.forward(torch.FloatTensor(X))\n",
    "    loss = loss_function(out, torch.FloatTensor(X))\n",
    "        \n",
    "    optim.zero_grad()\n",
    "        \n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "        \n",
    "    epoch += 1\n",
    "    \n",
    "    if (epoch % 1000 == 0):\n",
    "        print(\"epoch {}, loss {}\".format(epoch, loss))\n",
    "    \n",
    "test = autoencoder.A.detach().numpy()\n",
    "\n",
    "\n",
    "\n",
    "# # pca_clr = CodaPCA.CLRPCA(2)\n",
    "# # pca_clr.fit(features)\n",
    "# # test = pca_clr.transform(features)\n",
    "\n",
    "# pca = CodaPCA.CodaPCA(2,lrate=1e-3,nn_shape=[100,100], alg=CodaPCA.Alg.CODAPCA)\n",
    "# pca.fit(features)\n",
    "\n",
    "\n",
    "# test = pca.transform(features)\n",
    "\n",
    "plt.scatter(x = test[adult_inds][:,0], y = test[adult_inds][:,1], c =\"red\")\n",
    "plt.scatter(x = test[child_inds][:,0], y = test[child_inds][:,1], c =\"orange\")\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

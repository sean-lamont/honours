{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoDA_Regress(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, dimension, encoder_shape, decoder_shape):\n",
    "        super(CoDA_Regress, self).__init__()\n",
    "        \n",
    "        #define regression layer\n",
    "        self.linear = nn.Linear(dimension, 1)\n",
    "        \n",
    "        encoder_dict = OrderedDict()\n",
    "        \n",
    "        #first layer will be twice input size, since we are feeding in both c_kl and X \n",
    "        encoder_dict[\"layer0\"] = nn.Linear(2 * input_dim, encoder_shape[0])\n",
    "\n",
    "        for i in range(0,len(encoder_shape)-1):\n",
    "            encoder_dict[\"layer\"  + str(i)] = nn.Linear(encoder_shape[i], encoder_shape[i+1])\n",
    "            encoder_dict[\"layer_ac\"  + str(i)] = nn.ELU()\n",
    "        encoder_dict[\"final_layer\"] = nn.Linear(encoder_shape[-1], dimension)\n",
    "        encoder_dict[\"final_ac\"] = nn.ELU()\n",
    "\n",
    "        self.encoder = nn.Sequential(encoder_dict)\n",
    "        \n",
    "        decoder_dict = OrderedDict()\n",
    "        decoder_dict[\"layer0\"] = nn.Linear(dimension, decoder_shape[0])\n",
    "\n",
    "        for i in range(0,len(decoder_shape)-1):\n",
    "            decoder_dict[\"layer\"  + str(i)] = nn.Linear(decoder_shape[i], decoder_shape[i+1])\n",
    "            decoder_dict[\"layer_ac\"  + str(i)] = nn.ELU()\n",
    "\n",
    "        #final layer will map back to input dim\n",
    "        decoder_dict[\"final_layer\"] = nn.Linear(decoder_shape[-1], input_dim)\n",
    "        decoder_dict[\"final_ac\"] = nn.ELU()\n",
    "\n",
    "        self.decoder = nn.Sequential(decoder_dict)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        EPS = 1e-6   # to avoid log(0)\n",
    "\n",
    "        #run the encoding and store the low level representation as A\n",
    "        x_ckl = torch.log(torch.clamp(check(x), EPS, 1))\n",
    "        \n",
    "        #pass in both x and x_ckl as per paper\n",
    "        self.A = self.encoder(torch.cat((x, x_ckl), 1))\n",
    "        self.reconstruction = self.decoder(self.A)\n",
    "        self.pred = self.linear(self.A)\n",
    "        #return both the predicted target, and the reconstruction so both can be inputs to the combined loss\n",
    "        return self.pred, self.reconstruction\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Combined_Loss(torch.nn.Module):\n",
    "    def __init__(self, lam):\n",
    "        super(Combined_Loss,self).__init__()\n",
    "        self.CoDA_Loss = CoDA_Loss()\n",
    "        self.MSE = nn.MSELoss()\n",
    "        self.lam = lam\n",
    "        \n",
    "    def forward(self,Y,X,y_hat,y):\n",
    "        #X is original data, Y is CoDA reconstruction, y is targets, y_hat \n",
    "        #input needs to be normalised by g(x) (geometric mean) for X_hat\n",
    "        #TODO centering matrix? Reduce mean? Mask for near zero values?  \n",
    "        \n",
    "        #extract reconstruction and original data from concatenation\n",
    "        \n",
    "        return  self.MSE(y_hat, y) + self.lam * self.CoDA_Loss(Y,X)  \n",
    "\n",
    "class CoDA_Loss(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CoDA_Loss,self).__init__()\n",
    "        \n",
    "    def forward(self,Y,X):\n",
    "        #X is original data, Y is CoDA reconstruction\n",
    "        X_check = check(X)\n",
    "        coda_loss =  torch.sum(torch.exp(torch.clamp(Y, -30, 30))) - torch.sum(X_check * Y)\n",
    "        return coda_loss\n",
    "\n",
    "def check(X):\n",
    "    #assume input is tensor so we can use the numpy() method\n",
    "    assert type(X) == torch.Tensor\n",
    "    gmean = torch.prod(X, 1) ** (1./X.shape[1])\n",
    "    return torch.div(X.t(), torch.clamp(gmean, min=1e-8)).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 282.,  368.,  607.,  532.,  360.,  470.,  102.,  544.,  387.,  294.,\n",
       "         503.,  697.,  393.,  665.,  347.,  791.,  225.,  175.,  333.,  269.,\n",
       "         118.,  154.,  276.,  480.,  373.,  369.,  126.,  460.,  441.,  502.,\n",
       "         126.,  376.,  118.,  303.,  250.,  582.,   69.,  226.,  359.,  453.,\n",
       "         427.,  334.,  364.,  869.,  441.,  615.,  532.,  417.,  360.,  580.,\n",
       "         147.,  500.,  943.,  305., 1151.,  457.,  637.,  284.,  386.,  221.,\n",
       "         208.,  573.,  565.,  170.,  261., 1097.,  408.,   24.,  890.,  168.,\n",
       "          22.,  601.,  364.,  342.,  867.,  691.,  462.,  318.,  461.,  777.,\n",
       "         397.,  347.,  744.,  576.,  321.,  382.,  645.,  459.,  681.,  245.,\n",
       "         575.,  698.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Data 18. Compositions and total pebble counts of 92 glacial tills.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# headers = data[1]\n",
    "# features = data[0][:,co_feature_indices]\n",
    "# targets = data[0][:,target_index]\n",
    "    \n",
    "# #normalise the compositional features. TODO anything extra to deal with non compositional features?\n",
    "\n",
    "\n",
    "features = data[data.columns[1:-1]]\n",
    "targets = data[data.columns[-1]]\n",
    "\n",
    "features = np.array([feat/sum(feat) for feat in features.values])\n",
    "\n",
    "\n",
    "features = torch.FloatTensor(features)\n",
    "targets = torch.FloatTensor(targets)\n",
    "\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7750, 0.1950, 0.0300],\n",
       "        [0.7190, 0.2490, 0.0320],\n",
       "        [0.5070, 0.3610, 0.1320],\n",
       "        [0.5236, 0.4102, 0.0662],\n",
       "        [0.7000, 0.2650, 0.0350],\n",
       "        [0.6650, 0.3220, 0.0130],\n",
       "        [0.4310, 0.5530, 0.0160],\n",
       "        [0.5340, 0.3680, 0.0980],\n",
       "        [0.1550, 0.5440, 0.3010],\n",
       "        [0.3170, 0.4150, 0.2680],\n",
       "        [0.6570, 0.2780, 0.0650],\n",
       "        [0.7040, 0.2900, 0.0060],\n",
       "        [0.1740, 0.5360, 0.2900],\n",
       "        [0.1060, 0.6980, 0.1960],\n",
       "        [0.3820, 0.4310, 0.1870],\n",
       "        [0.1080, 0.5270, 0.3650],\n",
       "        [0.1840, 0.5070, 0.3090],\n",
       "        [0.0460, 0.4740, 0.4800],\n",
       "        [0.1560, 0.5040, 0.3400],\n",
       "        [0.3190, 0.4510, 0.2300],\n",
       "        [0.0950, 0.5350, 0.3700],\n",
       "        [0.1710, 0.4800, 0.3490],\n",
       "        [0.1050, 0.5540, 0.3410],\n",
       "        [0.0478, 0.5443, 0.4080],\n",
       "        [0.0260, 0.4520, 0.5220],\n",
       "        [0.1140, 0.5270, 0.3590],\n",
       "        [0.0670, 0.4690, 0.4640],\n",
       "        [0.0690, 0.4970, 0.4340],\n",
       "        [0.0400, 0.4490, 0.5110],\n",
       "        [0.0741, 0.5165, 0.4094],\n",
       "        [0.0480, 0.4950, 0.4570],\n",
       "        [0.0450, 0.4850, 0.4700],\n",
       "        [0.0660, 0.5210, 0.4130],\n",
       "        [0.0671, 0.4735, 0.4595],\n",
       "        [0.0741, 0.4565, 0.4695],\n",
       "        [0.0600, 0.4890, 0.4510],\n",
       "        [0.0630, 0.5380, 0.3990],\n",
       "        [0.0250, 0.4800, 0.4950],\n",
       "        [0.0200, 0.4780, 0.5020]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Data 5. Sand, silt, clay compositions of 39 sediment samples at different water depths in an Arctic lake.csv\")\n",
    "\n",
    "features = data[data.columns[1:-1]]\n",
    "targets = data[data.columns[-1]]\n",
    "\n",
    "features = np.array([feat/sum(feat) for feat in features.values])\n",
    "\n",
    "\n",
    "features = torch.FloatTensor(features)\n",
    "targets = torch.FloatTensor(targets)\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1000, loss 1539.879638671875\n",
      "epoch 2000, loss 923.87939453125\n",
      "epoch 3000, loss 652.4522094726562\n",
      "epoch 4000, loss 521.9324951171875\n",
      "epoch 5000, loss 445.07244873046875\n",
      "epoch 6000, loss 389.225830078125\n",
      "epoch 7000, loss 351.7326354980469\n",
      "epoch 8000, loss 327.64306640625\n",
      "epoch 9000, loss 311.1491394042969\n",
      "epoch 10000, loss 299.366455078125\n"
     ]
    }
   ],
   "source": [
    "#training code stub, read in data as X and targets as y\n",
    "#TODO substitute this into model class, and set up API similar to original CoDA-PCA paper\n",
    "\n",
    "X = features\n",
    "y = targets.reshape(-1,1)\n",
    "model = CoDA_Regress(X.shape[1], 2, [100,], [3,])\n",
    "#define the combined loss with hyperparameter lambda\n",
    "l = 1\n",
    "loss_function = Combined_Loss(l)\n",
    "optim = torch.optim.SGD(model.parameters(), lr = 1e-4)\n",
    "    \n",
    "for epoch in range(0,10000):\n",
    "    pred, recon = model.forward(torch.FloatTensor(X))\n",
    "    loss = loss_function(recon, torch.FloatTensor(X), pred, torch.FloatTensor(y))\n",
    "        \n",
    "    optim.zero_grad()\n",
    "        \n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "        \n",
    "    epoch += 1\n",
    "    \n",
    "    if (epoch % 1000 == 0):\n",
    "        print(\"epoch {}, loss {}\".format(epoch, loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoDA_Regress(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, dimension, encoder_shape, decoder_shape):\n",
    "        super(CoDA_Regress, self).__init__()\n",
    "        \n",
    "        #define regression layer\n",
    "        self.linear = nn.Linear(dimension, 1)\n",
    "        \n",
    "        encoder_dict = OrderedDict()\n",
    "        \n",
    "        #first layer will be twice input size, since we are feeding in both c_kl and X \n",
    "        encoder_dict[\"layer0\"] = nn.Linear(2 * input_dim, encoder_shape[0])\n",
    "\n",
    "        for i in range(0,len(encoder_shape)-1):\n",
    "            encoder_dict[\"layer\"  + str(i)] = nn.Linear(encoder_shape[i], encoder_shape[i+1])\n",
    "            encoder_dict[\"layer_ac\"  + str(i)] = nn.ELU()\n",
    "        encoder_dict[\"final_layer\"] = nn.Linear(encoder_shape[-1], dimension)\n",
    "        encoder_dict[\"final_ac\"] = nn.ELU()\n",
    "\n",
    "        self.encoder = nn.Sequential(encoder_dict)\n",
    "        \n",
    "        decoder_dict = OrderedDict()\n",
    "        decoder_dict[\"layer0\"] = nn.Linear(dimension, decoder_shape[0])\n",
    "\n",
    "        for i in range(0,len(decoder_shape)-1):\n",
    "            decoder_dict[\"layer\"  + str(i)] = nn.Linear(decoder_shape[i], decoder_shape[i+1])\n",
    "            decoder_dict[\"layer_ac\"  + str(i)] = nn.ELU()\n",
    "\n",
    "        #final layer will map back to input dim\n",
    "        decoder_dict[\"final_layer\"] = nn.Linear(decoder_shape[-1], input_dim)\n",
    "        decoder_dict[\"final_ac\"] = nn.ELU()\n",
    "\n",
    "        self.decoder = nn.Sequential(decoder_dict)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        EPS = 1e-6   # to avoid log(0)\n",
    "\n",
    "        #run the encoding and store the low level representation as A\n",
    "        x_ckl = torch.log(torch.clamp(check(x), EPS, 1))\n",
    "        \n",
    "        #pass in both x and x_ckl as per paper\n",
    "        A = self.encoder(torch.cat((x, x_ckl), 1))\n",
    "        reconstruction = self.decoder(A)\n",
    "        pred = self.linear(A)\n",
    "        #return both the predicted target, and the reconstruction so both can be inputs to the combined loss\n",
    "        return pred, reconstruction, A\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y, lam, lr):\n",
    "        \n",
    "        loss_function = Combined_Loss(lam)\n",
    "        optim = torch.optim.SGD(model.parameters(), lr = lr)\n",
    "    \n",
    "        for epoch in range(0,10000):\n",
    "            pred, recon, A = self.forward(torch.FloatTensor(X))\n",
    "            loss = loss_function(recon, torch.FloatTensor(X), pred, torch.FloatTensor(y))\n",
    "        \n",
    "            optim.zero_grad()\n",
    "        \n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        \n",
    "            epoch += 1\n",
    "    \n",
    "            if (epoch % 1000 == 0):\n",
    "                print(\"epoch {}, loss {}\".format(epoch, loss))\n",
    "        \n",
    "        return \n",
    "    \n",
    "    def transform(self, X):\n",
    "        pred, recon, A = self.forward(X)\n",
    "        return A\n",
    "    \n",
    "    def predict(self, X):\n",
    "        pred, recon, A = self.forward(X)\n",
    "        return pred\n",
    "    \n",
    "    #recon remains in CLR space, since the loss is derived for similarity to x_ckl\n",
    "    def project(self, X):\n",
    "        pred, recon, A = self.forward(X)\n",
    "        return recon\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Combined_Loss(torch.nn.Module):\n",
    "    def __init__(self, lam):\n",
    "        super(Combined_Loss,self).__init__()\n",
    "        self.CoDA_Loss = CoDA_Loss()\n",
    "        self.MSE = nn.MSELoss()\n",
    "        self.lam = lam\n",
    "        \n",
    "    def forward(self,Y,X,y_hat,y):\n",
    "        #X is original data, Y is CoDA reconstruction, y is targets, y_hat \n",
    "        #input needs to be normalised by g(x) (geometric mean) for X_hat\n",
    "        #TODO centering matrix? Reduce mean? Mask for near zero values?  \n",
    "        \n",
    "        #extract reconstruction and original data from concatenation\n",
    "        \n",
    "        return  self.MSE(y_hat, y) + self.lam * self.CoDA_Loss(Y,X)  \n",
    "\n",
    "class CoDA_Loss(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CoDA_Loss,self).__init__()\n",
    "        \n",
    "    def forward(self,Y,X):\n",
    "        #X is original data, Y is CoDA reconstruction\n",
    "        X_check = check(X)\n",
    "        coda_loss =  torch.sum(torch.exp(torch.clamp(Y, -30, 30))) - torch.sum(X_check * Y)\n",
    "        return coda_loss\n",
    "\n",
    "def check(X):\n",
    "    #assume input is tensor so we can use the numpy() method\n",
    "    assert type(X) == torch.Tensor\n",
    "    gmean = torch.prod(X, 1) ** (1./X.shape[1])\n",
    "    return torch.div(X.t(), torch.clamp(gmean, min=1e-8)).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 282.,  368.,  607.,  532.,  360.,  470.,  102.,  544.,  387.,  294.,\n",
       "         503.,  697.,  393.,  665.,  347.,  791.,  225.,  175.,  333.,  269.,\n",
       "         118.,  154.,  276.,  480.,  373.,  369.,  126.,  460.,  441.,  502.,\n",
       "         126.,  376.,  118.,  303.,  250.,  582.,   69.,  226.,  359.,  453.,\n",
       "         427.,  334.,  364.,  869.,  441.,  615.,  532.,  417.,  360.,  580.,\n",
       "         147.,  500.,  943.,  305., 1151.,  457.,  637.,  284.,  386.,  221.,\n",
       "         208.,  573.,  565.,  170.,  261., 1097.,  408.,   24.,  890.,  168.,\n",
       "          22.,  601.,  364.,  342.,  867.,  691.,  462.,  318.,  461.,  777.,\n",
       "         397.,  347.,  744.,  576.,  321.,  382.,  645.,  459.,  681.,  245.,\n",
       "         575.,  698.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Data 18. Compositions and total pebble counts of 92 glacial tills.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# headers = data[1]\n",
    "# features = data[0][:,co_feature_indices]\n",
    "# targets = data[0][:,target_index]\n",
    "    \n",
    "# #normalise the compositional features. TODO anything extra to deal with non compositional features?\n",
    "\n",
    "\n",
    "features = data[data.columns[1:-1]]\n",
    "targets = data[data.columns[-1]]\n",
    "\n",
    "features = np.array([feat/sum(feat) for feat in features.values])\n",
    "\n",
    "\n",
    "features = torch.FloatTensor(features)\n",
    "targets = torch.FloatTensor(targets)\n",
    "\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7750, 0.1950, 0.0300],\n",
       "        [0.7190, 0.2490, 0.0320],\n",
       "        [0.5070, 0.3610, 0.1320],\n",
       "        [0.5236, 0.4102, 0.0662],\n",
       "        [0.7000, 0.2650, 0.0350],\n",
       "        [0.6650, 0.3220, 0.0130],\n",
       "        [0.4310, 0.5530, 0.0160],\n",
       "        [0.5340, 0.3680, 0.0980],\n",
       "        [0.1550, 0.5440, 0.3010],\n",
       "        [0.3170, 0.4150, 0.2680],\n",
       "        [0.6570, 0.2780, 0.0650],\n",
       "        [0.7040, 0.2900, 0.0060],\n",
       "        [0.1740, 0.5360, 0.2900],\n",
       "        [0.1060, 0.6980, 0.1960],\n",
       "        [0.3820, 0.4310, 0.1870],\n",
       "        [0.1080, 0.5270, 0.3650],\n",
       "        [0.1840, 0.5070, 0.3090],\n",
       "        [0.0460, 0.4740, 0.4800],\n",
       "        [0.1560, 0.5040, 0.3400],\n",
       "        [0.3190, 0.4510, 0.2300],\n",
       "        [0.0950, 0.5350, 0.3700],\n",
       "        [0.1710, 0.4800, 0.3490],\n",
       "        [0.1050, 0.5540, 0.3410],\n",
       "        [0.0478, 0.5443, 0.4080],\n",
       "        [0.0260, 0.4520, 0.5220],\n",
       "        [0.1140, 0.5270, 0.3590],\n",
       "        [0.0670, 0.4690, 0.4640],\n",
       "        [0.0690, 0.4970, 0.4340],\n",
       "        [0.0400, 0.4490, 0.5110],\n",
       "        [0.0741, 0.5165, 0.4094],\n",
       "        [0.0480, 0.4950, 0.4570],\n",
       "        [0.0450, 0.4850, 0.4700],\n",
       "        [0.0660, 0.5210, 0.4130],\n",
       "        [0.0671, 0.4735, 0.4595],\n",
       "        [0.0741, 0.4565, 0.4695],\n",
       "        [0.0600, 0.4890, 0.4510],\n",
       "        [0.0630, 0.5380, 0.3990],\n",
       "        [0.0250, 0.4800, 0.4950],\n",
       "        [0.0200, 0.4780, 0.5020]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Data 5. Sand, silt, clay compositions of 39 sediment samples at different water depths in an Arctic lake.csv\")\n",
    "\n",
    "features = data[data.columns[1:-1]]\n",
    "targets = data[data.columns[-1]]\n",
    "\n",
    "features = np.array([feat/sum(feat) for feat in features.values])\n",
    "\n",
    "\n",
    "features = torch.FloatTensor(features)\n",
    "targets = torch.FloatTensor(targets)\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1000, loss 268.6265869140625\n",
      "epoch 2000, loss 265.5070495605469\n",
      "epoch 3000, loss 263.0506896972656\n",
      "epoch 4000, loss 260.69171142578125\n",
      "epoch 5000, loss 258.3607177734375\n",
      "epoch 6000, loss 256.0971984863281\n",
      "epoch 7000, loss 254.01206970214844\n",
      "epoch 8000, loss 252.25941467285156\n",
      "epoch 9000, loss 250.92210388183594\n",
      "epoch 10000, loss 250.00721740722656\n"
     ]
    }
   ],
   "source": [
    "#training code stub, read in data as X and targets as y\n",
    "#TODO substitute this into model class, and set up API similar to original CoDA-PCA paper\n",
    "\n",
    "X = features\n",
    "y = targets.reshape(-1,1)\n",
    "model = CoDA_Regress(X.shape[1], 2, [100,], [3,])\n",
    "#define the combined loss with hyperparameter lambda\n",
    "# l = 1\n",
    "# loss_function = Combined_Loss(l)\n",
    "# optim = torch.optim.SGD(model.parameters(), lr = 1e-4)\n",
    "    \n",
    "# for epoch in range(0,10000):\n",
    "#     pred, recon = model.forward(torch.FloatTensor(X))\n",
    "#     loss = loss_function(recon, torch.FloatTensor(X), pred, torch.FloatTensor(y))\n",
    "        \n",
    "#     optim.zero_grad()\n",
    "        \n",
    "#     loss.backward()\n",
    "#     optim.step()\n",
    "        \n",
    "#     epoch += 1\n",
    "    \n",
    "#     if (epoch % 1000 == 0):\n",
    "#         print(\"epoch {}, loss {}\".format(epoch, loss))\n",
    "\n",
    "model.fit(torch.FloatTensor(X),  torch.FloatTensor(y), 1, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2842a325ac8>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = model.transform(X).detach().numpy()\n",
    "plt.scatter(test[:,0], test[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch     0] L=  3.2262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x284326e9e10>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFtxJREFUeJzt3X+sXvV92PH3B9uQ26iLSUwCvsY1qMgKKe28XdF1/mNZITGJUuzQZCOdNNq0srQNVZUqq0aWRsU0QWbtnzXRMi+LSqq2kGVgXEFqIF7E1ImOy2xwCLhxWCruvSg4IU7bcVds57M/7rnO9fXz695zfJ7zPOf9kq7uc87z9fP9+Mh+Pud8f0ZmIklqn8uGHYAkaThMAJLUUiYASWopE4AktZQJQJJaygQgSS1lApCkljIBSFJLmQAkqaXWDjuAXjZs2JBbtmwZdhiSNDKef/7572XmVYOUbXQC2LJlC9PT08MOQ5JGRkT85aBlbQKSpJYyAUhSS5kAJKmlTACS1FImAElqKROAJLVUo4eBrtbBo7PsP3yCudPzbFw/wZ4dW9m1bXLYYUlSo4xdAjh4dJZ7HjnO/JlzAMyenueeR44DmAQkaYmxawLaf/jE+S//RfNnzrH/8IkhRSRJzTR2CWDu9PyKzktSW41dAti4fmJF5yWprcYuAezZsZWJdWsuODexbg17dmwdUkSS1Exj1wm82NHrKCBJ6m3sEgAsJAG/8CWpt7FrApIkDcYEIEktVUkTUER8EfgY8EZm/kyH9z8IPAb8n+LUI5l5XxV1N4WzjyWNmqr6AH4f+CzwpR5l/kdmfqyi+hrF2ceSRlElTUCZ+QzwZhWfNYqcfbyQBLc/cITr9j7O9geOcPDo7LBDktRHnX0AvxARL0TEVyPiA90KRcTuiJiOiOlTp07VGN7qtX328eIT0OzpeZIfPwGZBKRmqysB/G/gpzLz54DfAw52K5iZBzJzKjOnrrpqoI3th67ts499ApJGUy0JIDP/KjP/pnj9BLAuIjbUUXcd2j77uO1PQNKoqmUiWERcDXw3MzMibmYh8Xy/jrrr0IbZx71GOW1cP8Fshy/7tjwBSaOqqmGgfwx8ENgQETPAvcA6gMz8PPAJ4F9ExFlgHrgzM7OKuptinGcf9xvltGfH1gveh3Y9AUmjqpIEkJmf6vP+Z1kYJqoR1KuNf2niG+cnIGkcjeVaQKpWt7b82dPzHDw6ez4J+IUvjRaXglBfvdryHe4pjS4TgPrqNMppkcM9pdFlE5D6Wmza+a2Hj3V83+Ge0mjyCUAD2bVtksmWT3iTxo0JQANr+4Q3adzYBKSBOdxTGi8mAK2Iwz2l8WEC6MDNXSS1gQlgGTd3kdQWJoBl+i17oOHzCU2qhglgGZc2bjaf0KTqOAx0mbZv7tJ0bj4jVccEsIxj3ZvNJzSpOiaAZXZtm+T+O25icv0EAUyun+D+O26yeaEhfEKTqmMfQAeOdW8uN5+RqlPJE0BEfDEi3oiIb3R5PyLiP0TEyYh4MSL+XhX1qn18QpOqU9UTwO+zsOPXl7q8/xHghuLn54H/WPyWVswnNKkalTwBZOYzwJs9iuwEvpQLngXWR8Q1VdQtSVqdujqBJ4HXlhzPFOcuEhG7I2I6IqZPnTpVS3CS1EZ1dQJHh3PZqWBmHgAOAExNTXUso9HlLF6pOepKADPAtUuONwFzNdWthnAWr9QsdTUBHQL+eTEa6B8AP8zM12uqWw3hLF6pWSp5AoiIPwY+CGyIiBngXmAdQGZ+HngC+ChwEngL+LUq6tVocRav1CyVJIDM/FSf9xP4V1XUpdG1cf0Esx2+7OuYxWvfg3Qxl4JQbYa1ztJi38Ps6XmSH/c9HDw6e0nrlZrOBKDaDGsWr30PUmeuBaRaDWMWr30PUmc+AWjsuYKo1JkJQGPPPR6kzmwC0thbbHJyFJB0IROAWuFS9T04vFSjzAQgrZJLW2jU2QcgrZLDSzXqTADSKjm8VKPOBCCtksNLNepMANIqObxUo85OYGmVHF6qUWcCkEpwg3qNMpuAJKmlTACS1FKVJICIuC0iTkTEyYjY2+H9X42IUxFxrPj5jSrqlSStXuk+gIhYA3wO+BALm78/FxGHMvOby4o+nJl3l61PklSNKp4AbgZOZuarmfk28BCws4LPlSRdQlUkgEngtSXHM8W55X45Il6MiK9ExLXdPiwidkfEdERMnzp1qoLwJEmdVJEAosO5XHb8J8CWzPxZ4GngwW4flpkHMnMqM6euuuqqCsKTJHVSRQKYAZbe0W8C5pYWyMzvZ+bfFof/Gfj7FdQrSSqhigTwHHBDRFwXEZcDdwKHlhaIiGuWHN4OvFxBvZKkEkqPAsrMsxFxN3AYWAN8MTNfioj7gOnMPAT8ZkTcDpwF3gR+tWy9kqRyInN5c31zTE1N5fT09LDDkKSRERHPZ+bUIGVdC0hqELeYVJ1MAFJDuMWk6uZaQFJDuMWk6mYCkBrCLSZVNxOA1BBuMam6mQCkhnCLSdXNTmCpIdxiUnUzAUgN4haTqpNNQJLUUiYASWopE4AktZQJQJJaygQgSS1lApCklnIYqDSGXFVUgzABSGPGVUU1qEqagCLitog4EREnI2Jvh/eviIiHi/f/PCK2VFGvpIu5qqgGVfoJICLWAJ8DPsTCBvHPRcShzPzmkmK/DvwgM386Iu4EPgP807J1S7rYpVhV1Cal8VTFE8DNwMnMfDUz3wYeAnYuK7MTeLB4/RXgloiICuqWtEzVq4ouNinNnp4n+XGT0sGjsyWiVBNUkQAmgdeWHM8U5zqWycyzwA+B91RQt6Rlql5V1Cal8VVFJ3CnO/nlO80PUmahYMRuYDfA5s2by0UmtVDVq4q6Uc34qiIBzADXLjneBMx1KTMTEWuBdwFvdvqwzDwAHACYmprqmCQk9VblqqIb108w2+HL3o1qRl8VTUDPATdExHURcTlwJ3BoWZlDwF3F608ARzLTL3dpBLhRzfgq/QSQmWcj4m7gMLAG+GJmvhQR9wHTmXkI+C/AH0TESRbu/O8sW6+kerhRzfiKJt+IT01N5fT09LDDkKSRERHPZ+bUIGVdC0iSWsoEIEktZQKQpJYyAUhSS5kAJKmlTACS1FImAElqKROAJLWUCUCSWsoEIEktZQKQpJYyAUhSS5kAJKmlTACS1FImAElqKROAJLVUqQQQEe+OiKci4lvF7yu7lDsXEceKn+XbRUqShqDsE8Be4GuZeQPwteK4k/nM/LvFz+0l65QkVaBsAtgJPFi8fhDYVfLzJEk1KZsA3peZrwMUv9/bpdw7ImI6Ip6NCJOEJDXA2n4FIuJp4OoOb+1bQT2bM3MuIq4HjkTE8cz8dpf6dgO7ATZv3ryCKiRJK9E3AWTmrd3ei4jvRsQ1mfl6RFwDvNHlM+aK369GxNeBbUDHBJCZB4ADAFNTU9n3byBJWpWyTUCHgLuK13cBjy0vEBFXRsQVxesNwHbgmyXrlTRCDh6dZfsDR7hu7+Nsf+AIB4/ODjskUT4BPAB8KCK+BXyoOCYipiLiC0WZ9wPTEfEC8N+BBzLTBCC1xMGjs9zzyHFmT8+TwOzpee555LhJoAH6NgH1kpnfB27pcH4a+I3i9f8EbipTj6RmO3h0lv2HTzB3ep6N6yfYs2Mru7ZNArD/8Anmz5y7oPz8mXPsP3zifBkNR6kEIEmLd/iLX/KLd/gAu7ZNMnd6vuOf63Ze9XEpCEml9LrDB9i4fqLjn+t2XvUxAUgqpd8d/p4dW5lYt+aC9ybWrWHPjq2XPDb1ZhOQpFI2rp9gtkMSWLzDX9oX0KmPYFC9+hm0OiYASaXs2bH1gj4AuPgOf9e2yVJf1v36GbQ6JgBJpXS7wwfY/sCRSu7YHUl0aZgAJJW2/A6/ijv2pU0+3ZYEcCRROXYCS6pcv5FB/SyfPNaNI4nKMQFIqlzZsf+dEshyjiQqzwQgqXJlx/73ShQBTK6f4P47brL9vyT7ACRVbpCRQb10G1o6uX6CP9v7i5XF2XY+AUiq3K5tk9x/x01Mrp9Y1R27k8fq4ROANEJGaTJUmbH/VU0eU28mAGlEtG0yVNnJY+rPJiBpRJQdWiktZwKQRoTLKqtqpRJARHwyIl6KiB9FxFSPcrdFxImIOBkRe8vUKbWVyyqramWfAL4B3AE8061ARKwBPgd8BLgR+FRE3FiyXql1HBmjqpXdEvJlgIjoVexm4GRmvlqUfQjYiRvDSyviyBhVrY5RQJPAa0uOZ4Cfr6Feaew4MkZV6psAIuJp4OoOb+3LzMcGqKPT40HX9Z0iYjewG2Dz5s0DfLykthqleRFN1DcBZOatJeuYAa5dcrwJmOtR3wHgAMDU1FSvhQAltVjb5kVcCnU0AT0H3BAR1wGzwJ3Ar9RQr6Qx0elOv9u8iN/+8guASWAQZYeBfjwiZoBfAB6PiMPF+Y0R8QRAZp4F7gYOAy8DX87Ml8qFLaktlu8NsHin32mxOIBzmdzzyHEOHp2tN9ARFJnNbWWZmprK6enpYYchaYi2P3Ck45f9mgjO9fj+auvKoRHxfGZ2nZe1lDOBJTVat5nO5zIvmhcxyJ/Tj5kAJDVat5nOi0tMr+kyD8kZ0v2ZACQ1Wq8Z0Lu2TfLv/8nPdXwSeOvts/YD9OFy0JIard8M6MXfv3voJU7Pnzn/537w1hmHhfZhJ7CksdCts7htncF2AktqHZfLXjkTgKSx4HLZK2cCkDQWXC575ewEljQWXC575UwAksaGy2WvjE1AktRSJgBJaimbgCS1Xls3ljEBSGq1KjeWGbVEYhOQpFbrtrHM/sMnVvQ53fYtaPJ6RD4BSGq1QWYQD3Jn3yuRNPUpoFQCiIhPAr8LvB+4OTM7LtwTEd8B/ho4B5wddJ0KSbrUNq6f6LiG0GUR5+/eezURLSaHbjuUNXkpirJPAN8A7gD+0wBl/3Fmfq9kfZJUmYNHZ3nr7bMd31vcWvKKtZf1bCJamhw6afJSFKUSQGa+DBBdNmSQpKZa3vnbyfyZc13fnzs937HZZ6mARi9FUVcncAJPRsTzEbG7pjolqat+X979vGtiXddmn0VJs/ci6PsEEBFPA1d3eGtfZj42YD3bM3MuIt4LPBURr2TmM13q2w3sBti8efOAHy9JKzNo2/yVP7GO/3fmRxcki3WXBf+3S9PRUpMNbv6BARJAZt5atpLMnCt+vxERjwI3Ax0TQGYeAA7AwoYwZeuWpE66df4uNbFuDff+0geACxeZe+vts/zgrTN9/2yTm3+ghmGgEfFO4LLM/Ovi9YeB+y51vZLUy54dWy/qA1i3Jnjn5Wv54fyZrltPAly39/Genz05ApPAoPww0I8DvwdcBTweEccyc0dEbAS+kJkfBd4HPFp0FK8F/igz/7Rk3JJUSpnlo7s9PYza9pPuCSxJK9RpBNHEujXcf8dNQ7/rX8mewM4ElqQVGpfNZ0wAklRYyWJu47D5jAlAklj9qqCjtgLoUiYASWJ1i7n1SxpNTw4mAElisFVBl+uWNH77yy/wWw8fI1iYDQzl9hm4VNwPQJLovmhbr8XcuiWHc8XoyuVjLFezz8ClZAKQJBYmhk2sW3PBuX6zeVez0meTloc2AUgSC80y999xE5PrJwgWJnX1G9ffKWn006Tloe0DkKTCSod2Lp8PcFnE+eafTpY/UQy7k9gEIEklLE0anWYIL3YEL18fqMrN6FfLBCBJFVnJDOEm7CFsApCkCg3ajLSaYadVsxNYkoZgNcNOq2YCkKQhWM2w06rZBCRJQ9CEFUVNAJI0JMNeUbRUE1BE7I+IVyLixYh4NCLWdyl3W0SciIiTEbG3TJ2SpGqU7QN4CviZzPxZ4C+Ae5YXiIg1wOeAjwA3Ap+KiBtL1itJKqlUAsjMJzPzbHH4LLCpQ7GbgZOZ+Wpmvg08BOwsU68kqbwqRwF9Gvhqh/OTwGtLjmeKc5KkIerbCRwRTwNXd3hrX2Y+VpTZB5wF/rDTR3Q413WxjIjYDewG2Lx5c7/wJGksDGNdoL4JIDNv7fV+RNwFfAy4JbPjKkgzwLVLjjcBcz3qOwAcAJiamuq+qpIkjaBOX/TAUNYFKjUMNCJuA34H+EeZ+VaXYs8BN0TEdcAscCfwK2XqlaRR1G0BuCvWXjaUdYHK9gF8FvhJ4KmIOBYRnweIiI0R8QRA0Ul8N3AYeBn4cma+VLJeSRo53RaAOz1/pmP5S70uUKkngMz86S7n54CPLjl+AniiTF2SNOpW+oV+qdcFci0gSapJty/0K39i3VDWBTIBSFJNui0Ad+8vfWDF21FWwbWAJKkmSxeAmz09z5qI8529e3Zs5c/2/mKt8fgEIEk12rVt8vyTwOL+wYujgQ4ena01FhOAJNWs13aQdTIBSFLNmrAdJJgAJKl2TdgOEkwAklS7JmwHCY4CkqTaNWE7SDABSNJQDHs7SLAJSJJaywQgSS1lApCkljIBSFJLmQAkqaVMAJLUUtF5G99miIhTwF/WUNUG4Hs11FOlUYwZRjNuY67PKMbdtJh/KjOvGqRgoxNAXSJiOjOnhh3HSoxizDCacRtzfUYx7lGMeZFNQJLUUiYASWopE8CCA8MOYBVGMWYYzbiNuT6jGPcoxgzYByBJreUTgCS1VCsTQET8m4h4MSKORcSTEbGxS7m7IuJbxc9ddce5LJb9EfFKEfejEbG+S7nvRMTx4u82XXecHeIZNO7bIuJERJyMiL11x7kslk9GxEsR8aOI6Dq6o0nXegUxN+Y6F/G8OyKeKv6PPRURV3Ypd664zsci4lDdcRYx9Lx2EXFFRDxcvP/nEbGl/ihXKDNb9wP8nSWvfxP4fIcy7wZeLX5fWby+cogxfxhYW7z+DPCZLuW+A2wY9jVeSdzAGuDbwPXA5cALwI1DjPn9wFbg68BUj3KNudaDxNy061zE9O+AvcXrvT3+Xf/NkOPse+2Af7n4XQLcCTw87H8X/X5a+QSQmX+15PCdQKeOkB3AU5n5Zmb+AHgKuK2O+DrJzCcz82xx+CywaVixrMSAcd8MnMzMVzPzbeAhYGddMS6XmS9nZr27c5c0YMyNus6FncCDxesHgV1DjKWXQa7d0r/LV4BbIiJqjHHFWpkAACLi30bEa8A/A/51hyKTwGtLjmeKc03waeCrXd5L4MmIeD4idtcY0yC6xd3ka91Lk691J028zu/LzNcBit/v7VLuHRExHRHPRsQwksQg1+58meKm54fAe2qJbpXGdkewiHgauLrDW/sy87HM3Afsi4h7gLuBe5d/RIc/e0mHTPWLuSizDzgL/GGXj9memXMR8V7gqYh4JTOfuTQRL6gg7kZe6wHUeq0riLn26wy9417Bx2wurvX1wJGIOJ6Z364mwoEMcu2Gcn3LGNsEkJm3Dlj0j4DHuTgBzAAfXHK8iYX21UumX8xFR/THgFuyaGjs8Blzxe83IuJRFh5dL2kCqCDuGeDaJcebgLnqIrzYCv599PqMWq91BTHXfp2hd9wR8d2IuCYzX4+Ia4A3unzG4rV+NSK+DmxjoU2+LoNcu8UyMxGxFngX8GY94a1OK5uAIuKGJYe3A690KHYY+HBEXFmMTPhwcW4oIuI24HeA2zPzrS5l3hkRP7n4moWYv1FflB1j6hs38BxwQ0RcFxGXs9CBNpSRHoNq4rUeQBOv8yFgcYTdXcBFTzLF/8EritcbgO3AN2uLcMEg127p3+UTwJFuN2qNMexe6GH8AP+Nhf+sLwJ/AkwW56eALywp92ngZPHza0OO+SQL7YvHip/F0QYbgSeK19ezMDrhBeAlFpoGhn2t+8ZdHH8U+AsW7uqGGjfwcRbu5v4W+C5wuOnXepCYm3adi3jeA3wN+Fbx+93F+fP/F4F/CBwvrvVx4NeHFOtF1w64j4WbG4B3AP+1+Df/v4Drh319+/04E1iSWqqVTUCSJBOAJLWWCUCSWsoEIEktZQKQpJYyAUhSS5kAJKmlTACS1FL/H9ZJB05ZAnWEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Data 5. Sand, silt, clay compositions of 39 sediment samples at different water depths in an Arctic lake.csv\")\n",
    "\n",
    "features = data[data.columns[1:-1]]\n",
    "targets = data[data.columns[-1]]\n",
    "\n",
    "features = np.array([feat/sum(feat) for feat in features.values])\n",
    "\n",
    "\n",
    "features = torch.FloatTensor(features)\n",
    "targets = torch.FloatTensor(targets)\n",
    "\n",
    "import CodaPCA\n",
    "pca = CodaPCA.CodaPCA(2,lrate=1e-3,nn_shape=[50,50], alg=CodaPCA.Alg.CODAPCA)\n",
    "\n",
    "test = pca.fit_transform(features)\n",
    "\n",
    "plt.scatter(test[:,0], test[:,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

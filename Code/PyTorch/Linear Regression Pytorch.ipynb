{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.datasets import load_boston\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, x_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.model = nn.Linear(x_dim, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor(load_boston()['data'])\n",
    "Y = torch.FloatTensor(load_boston()['target'])\n",
    "Y = torch.FloatTensor(Y).reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 16012.25\n",
      "epoch 2, loss 14086.291015625\n",
      "epoch 3, loss 12393.912109375\n",
      "epoch 4, loss 10906.78515625\n",
      "epoch 5, loss 9600.0107421875\n",
      "epoch 6, loss 8451.71875\n",
      "epoch 7, loss 7442.685546875\n",
      "epoch 8, loss 6556.02099609375\n",
      "epoch 9, loss 5776.88330078125\n",
      "epoch 10, loss 5092.23095703125\n",
      "epoch 11, loss 4490.603515625\n",
      "epoch 12, loss 3961.931640625\n",
      "epoch 13, loss 3497.366943359375\n",
      "epoch 14, loss 3089.134521484375\n",
      "epoch 15, loss 2730.401123046875\n",
      "epoch 16, loss 2415.164306640625\n",
      "epoch 17, loss 2138.1474609375\n",
      "epoch 18, loss 1894.7158203125\n",
      "epoch 19, loss 1680.7952880859375\n",
      "epoch 20, loss 1492.8072509765625\n",
      "epoch 21, loss 1327.606201171875\n",
      "epoch 22, loss 1182.428955078125\n",
      "epoch 23, loss 1054.84619140625\n",
      "epoch 24, loss 942.7245483398438\n",
      "epoch 25, loss 844.1888427734375\n",
      "epoch 26, loss 757.5912475585938\n",
      "epoch 27, loss 681.4837036132812\n",
      "epoch 28, loss 614.5943603515625\n",
      "epoch 29, loss 555.80517578125\n",
      "epoch 30, loss 504.1336669921875\n",
      "epoch 31, loss 458.716796875\n",
      "epoch 32, loss 418.7958984375\n",
      "epoch 33, loss 383.7046203613281\n",
      "epoch 34, loss 352.85723876953125\n",
      "epoch 35, loss 325.7389831542969\n",
      "epoch 36, loss 301.8978271484375\n",
      "epoch 37, loss 280.936279296875\n",
      "epoch 38, loss 262.5052490234375\n",
      "epoch 39, loss 246.29786682128906\n",
      "epoch 40, loss 232.04452514648438\n",
      "epoch 41, loss 219.50831604003906\n",
      "epoch 42, loss 208.48106384277344\n",
      "epoch 43, loss 198.77984619140625\n",
      "epoch 44, loss 190.24391174316406\n",
      "epoch 45, loss 182.7320098876953\n",
      "epoch 46, loss 176.12002563476562\n",
      "epoch 47, loss 170.2989044189453\n",
      "epoch 48, loss 165.17279052734375\n",
      "epoch 49, loss 160.65748596191406\n",
      "epoch 50, loss 156.67898559570312\n",
      "epoch 51, loss 153.17225646972656\n",
      "epoch 52, loss 150.08016967773438\n",
      "epoch 53, loss 147.35252380371094\n",
      "epoch 54, loss 144.9451904296875\n",
      "epoch 55, loss 142.8193817138672\n",
      "epoch 56, loss 140.9410400390625\n",
      "epoch 57, loss 139.28024291992188\n",
      "epoch 58, loss 137.81068420410156\n",
      "epoch 59, loss 136.5092315673828\n",
      "epoch 60, loss 135.35556030273438\n",
      "epoch 61, loss 134.33184814453125\n",
      "epoch 62, loss 133.42239379882812\n",
      "epoch 63, loss 132.61341857910156\n",
      "epoch 64, loss 131.89279174804688\n",
      "epoch 65, loss 131.24989318847656\n",
      "epoch 66, loss 130.67535400390625\n",
      "epoch 67, loss 130.1609649658203\n",
      "epoch 68, loss 129.69947814941406\n",
      "epoch 69, loss 129.28457641601562\n",
      "epoch 70, loss 128.91065979003906\n",
      "epoch 71, loss 128.5728302001953\n",
      "epoch 72, loss 128.26678466796875\n",
      "epoch 73, loss 127.98872375488281\n",
      "epoch 74, loss 127.7353286743164\n",
      "epoch 75, loss 127.50367736816406\n",
      "epoch 76, loss 127.29118347167969\n",
      "epoch 77, loss 127.09559631347656\n",
      "epoch 78, loss 126.9149398803711\n",
      "epoch 79, loss 126.74745178222656\n",
      "epoch 80, loss 126.59160614013672\n",
      "epoch 81, loss 126.44606018066406\n",
      "epoch 82, loss 126.30960845947266\n",
      "epoch 83, loss 126.18120574951172\n",
      "epoch 84, loss 126.05996704101562\n",
      "epoch 85, loss 125.94505310058594\n",
      "epoch 86, loss 125.83577728271484\n",
      "epoch 87, loss 125.73149871826172\n",
      "epoch 88, loss 125.63168334960938\n",
      "epoch 89, loss 125.53584289550781\n",
      "epoch 90, loss 125.44354248046875\n",
      "epoch 91, loss 125.35443115234375\n",
      "epoch 92, loss 125.26817321777344\n",
      "epoch 93, loss 125.18446350097656\n",
      "epoch 94, loss 125.1030502319336\n",
      "epoch 95, loss 125.02371215820312\n",
      "epoch 96, loss 124.9462661743164\n",
      "epoch 97, loss 124.87052917480469\n",
      "epoch 98, loss 124.79634094238281\n",
      "epoch 99, loss 124.72356414794922\n",
      "epoch 100, loss 124.65209197998047\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression(13)\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "optimiser = torch.optim.SGD(model.parameters(), lr = 0.0000001) #lower learning rate if loss is high\n",
    "\n",
    "for epoch in range(0,100):\n",
    "    \n",
    "    #mini batches: randomly shuffle the data, then run through a partition of the data in each mini batch \n",
    "    # go through all mini batches in a shuffle to form an epoch\n",
    "    \n",
    "    epoch += 1\n",
    "    \n",
    "    optimiser.zero_grad()\n",
    "    \n",
    "    out = model.forward(torch.FloatTensor(X))\n",
    "    \n",
    "    loss = loss_function(out, torch.FloatTensor(Y)) #divide by n\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimiser.step()\n",
    "\n",
    "            \n",
    "    print ('epoch {}, loss {}'.format(epoch, loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

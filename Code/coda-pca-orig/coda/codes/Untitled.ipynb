{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import CodaPCA\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from runpca import read_csv\n",
    "\n",
    "import os\n",
    "\n",
    "import sklearn\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "#change module for newer sklearn versions\n",
    "\n",
    "from sklearn.cross_validation  import cross_val_score\n",
    "\n",
    "from sklearn.cross_validation  import KFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#read in the data. Given an array of which files are regression, classification or unlabelled\n",
    "\n",
    "data_path = os.getcwd() + \"\\\\Aitchinson\"\n",
    "\n",
    "\n",
    "regression_list = [3,4,5,18,21,34,39]\n",
    "\n",
    "classification_list = [7,8,9,11,12,16,17,19,23,24,25,26,28,29,33,37]\n",
    "\n",
    "unlabelled_list=[1,2,6,10,13,14,15,20,22,27,30,31,32,35,36,38,40]\n",
    "\n",
    "\n",
    "\n",
    "r_files = []\n",
    "\n",
    "c_files = []\n",
    "\n",
    "u_files = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for file in os.listdir(data_path):\n",
    "\n",
    "    for i in regression_list:\n",
    "\n",
    "        if os.path.isfile(os.path.join(data_path,file)) and 'Data ' + str(i) + '.' in file:\n",
    "\n",
    "            r_files.append(\"Aitchinson/\" + file)\n",
    "\n",
    "    for i in classification_list:\n",
    "\n",
    "        if os.path.isfile(os.path.join(data_path,file)) and 'Data ' + str(i) + '.' in file:\n",
    "\n",
    "            c_files.append(\"Aitchinson/\" + file)\n",
    "\n",
    "    for i in unlabelled_list:\n",
    "\n",
    "        if os.path.isfile(os.path.join(data_path,file)) and 'Data ' + str(i) + '.' in file:\n",
    "\n",
    "            u_files.append(\"Aitchinson/\" + file)\n",
    "\n",
    "\n",
    "\n",
    "#need to specify where the the targets and features are in the dataset, and whether there are non compositional features\n",
    "\n",
    "\n",
    "\n",
    "def PCA_Regression(data, co_feature_indices, target_index, \n",
    "\n",
    "                   other_feature_indices = [], alg=CodaPCA.Alg.CODAPCA, verbose=False):\n",
    "\n",
    "    \n",
    "\n",
    "    #can loop through/optimise this in another way?\n",
    "\n",
    "    \n",
    "\n",
    "    headers = data[1]\n",
    "\n",
    "    features = data[0][:,co_feature_indices]\n",
    "\n",
    "    targets = data[0][:,target_index]\n",
    "\n",
    "    \n",
    "\n",
    "    #normalise the compositional features. TODO anything extra to deal with non compositional features?\n",
    "\n",
    "    features = np.array([feat/sum(feat) for feat in features])\n",
    "\n",
    "\n",
    "\n",
    "    #can be empty\n",
    "\n",
    "    extra_features = data[0][:,other_feature_indices]\n",
    "\n",
    "    \n",
    "\n",
    "    #TODO double check this\n",
    "\n",
    "    features = np.hstack([features, extra_features])\n",
    "\n",
    "    \n",
    "\n",
    "    #compute the CoDA-PCA projection \n",
    "\n",
    "    #TODO add component number as a hyperparameter to optimise \n",
    "\n",
    "    n_components=len(co_feature_indices)-2\n",
    "\n",
    "\n",
    "\n",
    "    pca = CodaPCA.CodaPCA(n_components,lrate=1e-3,nn_shape=[100,100], alg=alg)\n",
    "\n",
    "    pca.fit(features)\n",
    "\n",
    "    \n",
    "\n",
    "    Y_coda = pca.project(features)\n",
    "\n",
    "\n",
    "\n",
    "    pca_clr = CodaPCA.CLRPCA(n_components)\n",
    "\n",
    "    pca_clr.fit(features)\n",
    "\n",
    "    \n",
    "\n",
    "    Y_clr = pca_clr.project(features)\n",
    "\n",
    "\n",
    "    lm = Ridge()\n",
    "\n",
    "    #exp the projection to get out of clr space\n",
    "\n",
    "    coda_score = enhanced_cross_val(lm,np.exp(Y_coda), targets)\n",
    "\n",
    "    clr_score = enhanced_cross_val(lm,np.exp(Y_clr), targets) \n",
    "\n",
    "    naive_score = enhanced_cross_val(lm, features, targets)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if verbose:\n",
    "\n",
    "        print(\"CoDA-PCA:\")\n",
    "\n",
    "        print(coda_score)\n",
    "\n",
    "        print(\"CLR-PCA:\")\n",
    "\n",
    "        print(clr_score)\n",
    "\n",
    "        print (\"Naive regression:\")\n",
    "\n",
    "        print (naive_score)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    return coda_score,clr_score,naive_score\n",
    "\n",
    "\n",
    "\n",
    "#training methodology as described in:\n",
    "\n",
    "#https://papers.nips.cc/paper/3215-learning-with-transformation-invariant-kernels.pdf\n",
    "\n",
    "def enhanced_cross_val(model, features, targets):\n",
    "\n",
    "    assert len(features) == len(targets), \"Mismatch in length of features and targets\"\n",
    "\n",
    "    \n",
    "\n",
    "    #define the number of splits and folds uised in the parameter selection\n",
    "\n",
    "    #stick to smaller splits since we have small datasets\n",
    "\n",
    "    splits = 4\n",
    "\n",
    "    param_splits = 3\n",
    "\n",
    "    \n",
    "\n",
    "    #split data \n",
    "\n",
    "    kf = KFold(len(features), n_folds=splits)\n",
    "\n",
    "    kfold_scores = []\n",
    "\n",
    "    for train, test in kf:        \n",
    "\n",
    "        Y_train = targets[train]\n",
    "\n",
    "        X_train = features[train]\n",
    "\n",
    "        \n",
    "\n",
    "       \n",
    "\n",
    "        Y_test = targets[test]\n",
    "\n",
    "        X_test = features[test]\n",
    "\n",
    "        \n",
    "\n",
    "        #inner loop for parameter selection (regularisation term in Ridge Regression):\n",
    "\n",
    "        param_grid = [0.01,0.05,0.1,0.5,1.0,2.0,5.0,10.0,20.0,100.0]\n",
    "\n",
    "        for a in param_grid:\n",
    "\n",
    "            max_score = -np.inf\n",
    "\n",
    "            lm = Ridge(a)\n",
    "\n",
    "   \n",
    "\n",
    "            curr_score = np.mean(cross_val_score(lm, X_train, Y_train,cv=param_splits))\n",
    "\n",
    "            if curr_score > max_score:\n",
    "\n",
    "                max_score = curr_score\n",
    "\n",
    "                best_param = a\n",
    "\n",
    "        \n",
    "\n",
    "        #compute test score based on best parameter\n",
    "\n",
    "        lm = Ridge(best_param)\n",
    "\n",
    "        lm.fit(X_train, Y_train)\n",
    "\n",
    "        kfold_scores.append(lm.score(X_test, Y_test))\n",
    "\n",
    "        \n",
    "\n",
    "    return kfold_scores\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#can automate this if we had assume a certain structure for the indices of features and targets, or an array per dataset \n",
    "\n",
    "\n",
    "\n",
    "score_dict = {}\n",
    "\n",
    "\n",
    "data_18_scores = PCA_Regression(read_csv(r_files[0], normalize=False), co_feature_indices=[0,1,2,3], target_index=4)\n",
    "\n",
    "#other \"target\" also at 5\n",
    "\n",
    "score_dict['18'] = data_18_scores\n",
    "\n",
    "\n",
    "\n",
    "data_21_scores = PCA_Regression(read_csv(r_files[1], normalize=False), co_feature_indices=[0,1,2,3], target_index=4) \n",
    "\n",
    "score_dict['21'] = data_21_scores\n",
    "\n",
    "\n",
    "\n",
    "data_3_scores = PCA_Regression(read_csv(r_files[2], normalize=False), co_feature_indices=[0,1,2,3,4], target_index=5) \n",
    "\n",
    "score_dict['3'] = data_3_scores\n",
    "\n",
    "\n",
    "\n",
    "data_34_scores = PCA_Regression(read_csv(r_files[3], normalize=False), co_feature_indices=[0,1,2,3], target_index=4)\n",
    "\n",
    "score_dict['34'] = data_34_scores\n",
    "\n",
    "\n",
    "\n",
    "data_39_scores = PCA_Regression(read_csv(r_files[4], normalize=False), co_feature_indices=[0,1,2], target_index=3)\n",
    "\n",
    "score_dict['39'] = data_39_scores\n",
    "\n",
    "\n",
    "\n",
    "data_4_scores = PCA_Regression(read_csv(r_files[5], normalize=False), co_feature_indices=[0,1,2,3,4], target_index=5)\n",
    "\n",
    "score_dict['4'] = data_4_scores\n",
    "\n",
    "\n",
    "\n",
    "data_5_scores =PCA_Regression(read_csv(r_files[6], normalize=False), co_feature_indices=[0,1,2], target_index=3)\n",
    "\n",
    "score_dict['5'] = data_5_scores\n",
    "\n",
    "\n",
    "\n",
    "#note: plotly code works fine, but gives a jupyter warning when saving with a rendered table\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CodaPCA\n",
    "import CodaCl \n",
    "import PCACl\n",
    "import numpy as np\n",
    "from runpca import read_csv\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#change module for newer sklearn versions\n",
    "from sklearn.model_selection  import cross_val_score\n",
    "from sklearn.model_selection  import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import decomposition\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_dict = {}\n",
    "\n",
    "test_dict[(1,2,3)] = 1\n",
    "test_dict[(1,2,3)] = [1,3]\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhanced_cross_val(features, targets, folds):\n",
    "    assert len(features) == len(targets), \"Mismatch in length of features and targets\"\n",
    "    kfold_scores = []\n",
    "    for train, test in folds:\n",
    "        Y_train = targets[train]\n",
    "        X_train = features[train]\n",
    "               \n",
    "        Y_test = targets[test]\n",
    "        X_test = features[test]\n",
    "                \n",
    "        model = LogisticRegression(multi_class='auto', solver='lbfgs')\n",
    "        model.fit(X_train, Y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        kfold_scores.append(sklearn.metrics.accuracy_score(Y_test,y_pred))\n",
    "                \n",
    "    return kfold_scores\n",
    "\n",
    "#can automate this if we had assume a certain structure for the indices of features and targets, or an array per dataset \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coda_val(features, targets, n_components, folds, nn_shape,  lr,lam, epochs):\n",
    "    kfold_scores = []\n",
    "    for train, test in folds:        \n",
    "        Y_train = targets[train]\n",
    "        X_train = features[train]\n",
    "        \n",
    "       \n",
    "        Y_test = targets[test]\n",
    "        X_test = features[test]\n",
    "        \n",
    "        \n",
    "        model = PCACl.CoDA_Cl(13, n_components, 3, nn_shape[0], nn_shape[1])\n",
    "\n",
    "\n",
    "        val_arr, train_arr = model.fit(X_train, Y_train, lam, lr, train_size = int(len(X_train)*(3/4)), epochs=epochs)\n",
    "        \n",
    "#         print (\"Plot!\")\n",
    "        \n",
    "#         plt.plot(val_arr, c=\"red\")\n",
    "#         plt.plot(train_arr, c=\"blue\")\n",
    "        \n",
    "#         plt.ylim(bottom=min(train_arr))\n",
    "\n",
    "#         plt.show()\n",
    "        \n",
    "        pred = model.predict(torch.FloatTensor(X_test))\n",
    "        \n",
    "        pred = pred.exp().detach()     \n",
    "        _, index = torch.max(pred,1)  \n",
    "        pred = pred.numpy()\n",
    "        index = index.numpy()\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        kfold_scores.append(sklearn.metrics.accuracy_score(Y_test,index))\n",
    "                \n",
    "    return kfold_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_Classification(data, co_feature_indices, target_index, \n",
    "                   other_feature_indices = [], alg=CodaPCA.Alg.CODAPCA, verbose=True):\n",
    "       #can loop through/optimise this in another way?\n",
    "    \n",
    "    features = data[:,co_feature_indices]\n",
    "    \n",
    "    features_ = features\n",
    "    \n",
    "    targets = data[:,target_index]\n",
    "    \n",
    "    \n",
    "    #set up as int list, and subtract to get index so NLL loss works\n",
    "    targets = list(map(int,data[:,0]))\n",
    "    targets = [target - 1 for target in targets]\n",
    "\n",
    "    \n",
    "    #normalise the compositional features. TODO anything extra to deal with non compositional features?\n",
    "    #features = np.array([feat/sum(feat) for feat in features])\n",
    "\n",
    "    #can be empty\n",
    "    extra_features = data[:,other_feature_indices]\n",
    "    \n",
    "    #TODO double check this\n",
    "    features = np.hstack([features, extra_features])\n",
    "    \n",
    "\n",
    "    n_components=2\n",
    "    \n",
    "\n",
    "    pca_coda = CodaPCA.NonParametricCodaPCA(n_components)\n",
    "    pca_coda.fit(features)\n",
    "    \n",
    "    Y_coda = pca_coda.transform(features)\n",
    "\n",
    "    pca_clr = CodaPCA.CLRPCA(n_components)\n",
    "    pca_clr.fit(features)\n",
    "    \n",
    "    Y_clr = pca_clr.transform(features)\n",
    "    \n",
    "    \n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    features_ = sc.fit_transform(features)\n",
    "\n",
    "    \n",
    "    pca_reg = decomposition.PCA(n_components)\n",
    "    pca_reg.fit(features_)\n",
    "    \n",
    "    Y_pca = pca_reg.transform(features_)\n",
    "\n",
    "    splits = 4\n",
    "    #split data \n",
    "    kf = KFold(splits)\n",
    "        \n",
    "    folds = [i for i in kf.split(features)] \n",
    "\n",
    "    coda_score = enhanced_cross_val(Y_coda, np.array(targets), folds)\n",
    "    clr_score = enhanced_cross_val(Y_clr, np.array(targets), folds) \n",
    "    naive_score = enhanced_cross_val(Y_pca, np.array(targets), folds)\n",
    "\n",
    "#     import itertools\n",
    "#     nn_vals = [[[5,], [2,]]]#, [[10,],[5,]], [[10,5], [3,5]], [[50,], [20,]], [[50,20], [10,20]]]\n",
    "#     lr_vals = [1e-3]#, 1e-3, 5e-4,1e-4 ]\n",
    "#     lam_vals = [1e-12]#1e-12,5e-12,1e-11,5e-11,1e-10,5e-10,1e-5,1e-4,0.001,0.1,1,10,100]\n",
    "#     epoch_vals = [5000]\n",
    "\n",
    "#     param_list = list(itertools.product(*[nn_vals, lr_vals, lam_vals, epoch_vals]))\n",
    "# #     param_file = open(\"paramresultswineclass.txt\",\"w\") \n",
    "# #     param_file.write(\"Results from hyperparameter grid search:\\n\\n\") \n",
    "\n",
    "#     param_dict = {}\n",
    "        \n",
    "#     for params in param_list:\n",
    "#         nn_shape = params[0]\n",
    "#         lr = params[1]\n",
    "#         lam = params[2]\n",
    "#         n_epochs = params[3]\n",
    "\n",
    "#         score = coda_val(features, np.array(targets), 2, folds, nn_shape, lr, lam, n_epochs )\n",
    "\n",
    "#         param_dict[tuple([sum(nn_shape[0]) + sum(nn_shape[1]), lr, lam, n_epochs])] = np.mean(score)\n",
    "#         param_file.write(\"nn {}, lr {}, lam {}, epochs {}, num_samples {}, num_features {} \\nScore: {} \\nMean_score: {} \\n\\n\".format(nn_shape, lr, lam, n_epochs, len(features), len(co_feature_indices), score, np.mean(score)))\n",
    "\n",
    "#         param_file.close()\n",
    "\n",
    "    #codacl_score = coda_val(features, np.array(targets), n_components, folds)\n",
    "\n",
    "    nn_shape = [[5,], [2,]]\n",
    "    lr = 1e-3\n",
    "    lam = 1e-3\n",
    "    n_epochs = 10000\n",
    "\n",
    "    codacl_score = coda_val(features, np.array(targets), 2, folds, nn_shape, lr, lam, n_epochs )\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"CoDA-PCA:\")\n",
    "        print(coda_score)\n",
    "        print(\"CLR-PCA:\")\n",
    "        print(clr_score)\n",
    "        print (\"Naive Classification:\")\n",
    "        print (naive_score)\n",
    "        print (\"Coda Cl:\")\n",
    "        print (codacl_score)\n",
    "\n",
    "    return coda_score,clr_score,naive_score,codacl_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = pd.read_csv(\"wine.data\", header=None)\n",
    "\n",
    "data = wine.to_numpy()\n",
    "np.random.shuffle(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# param_dict = PCA_Classification(np.array(data), [1,2,3,4,5,6,7,8,9,10,11,12,13], 0)\n",
    "\n",
    "# with open('param_search.pik', 'wb') as f:\n",
    "#     dill.dump(param_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = open('param_search.pik','rb')\n",
    "\n",
    "# c = dill.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1000, loss 8.869213104248047\n",
      "epoch 2000, loss 8.458991050720215\n",
      "epoch 3000, loss 8.4513578414917\n",
      "epoch 4000, loss 8.451574325561523\n",
      "epoch 5000, loss 8.45173454284668\n",
      "epoch 6000, loss 8.451714515686035\n",
      "epoch 7000, loss 8.451815605163574\n",
      "epoch 8000, loss 8.451837539672852\n",
      "epoch 9000, loss 8.451715469360352\n",
      "epoch 10000, loss 8.451711654663086\n",
      "epoch 1000, loss 8.476215362548828\n",
      "epoch 2000, loss 8.350381851196289\n",
      "epoch 3000, loss 8.326128959655762\n",
      "epoch 4000, loss 8.3137845993042\n",
      "epoch 5000, loss 7.9741411209106445\n",
      "epoch 6000, loss 7.959311008453369\n",
      "epoch 7000, loss 7.953436851501465\n",
      "epoch 8000, loss 7.95097541809082\n",
      "epoch 9000, loss 7.949704170227051\n",
      "epoch 10000, loss 7.948823928833008\n",
      "epoch 1000, loss 8.4981689453125\n",
      "epoch 2000, loss 1.1112278699874878\n",
      "epoch 3000, loss 1.1050199270248413\n",
      "epoch 4000, loss 1.1042144298553467\n",
      "epoch 5000, loss 1.1040921211242676\n",
      "epoch 6000, loss 1.1041102409362793\n",
      "epoch 7000, loss 1.1044622659683228\n",
      "epoch 8000, loss 1.1041207313537598\n",
      "epoch 9000, loss 1.1041436195373535\n",
      "epoch 10000, loss 1.1041154861450195\n",
      "epoch 1000, loss 8.332013130187988\n",
      "epoch 2000, loss 8.236032485961914\n",
      "epoch 3000, loss 8.214065551757812\n",
      "epoch 4000, loss 8.202271461486816\n",
      "epoch 5000, loss 8.193644523620605\n",
      "epoch 6000, loss 8.186556816101074\n",
      "epoch 7000, loss 8.181151390075684\n",
      "epoch 8000, loss 8.178269386291504\n",
      "epoch 9000, loss 8.177534103393555\n",
      "epoch 10000, loss 8.177401542663574\n",
      "CoDA-PCA:\n",
      "[0.7555555555555555, 0.8666666666666667, 0.7954545454545454, 0.7727272727272727]\n",
      "CLR-PCA:\n",
      "[0.8888888888888888, 0.9777777777777777, 0.8409090909090909, 0.9545454545454546]\n",
      "Naive Classification:\n",
      "[0.9777777777777777, 0.9333333333333333, 0.9545454545454546, 0.9772727272727273]\n",
      "Coda Cl:\n",
      "[0.9777777777777777, 0.9333333333333333, 0.6363636363636364, 0.8636363636363636]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.7555555555555555,\n",
       "  0.8666666666666667,\n",
       "  0.7954545454545454,\n",
       "  0.7727272727272727],\n",
       " [0.8888888888888888,\n",
       "  0.9777777777777777,\n",
       "  0.8409090909090909,\n",
       "  0.9545454545454546],\n",
       " [0.9777777777777777,\n",
       "  0.9333333333333333,\n",
       "  0.9545454545454546,\n",
       "  0.9772727272727273],\n",
       " [0.9777777777777777,\n",
       "  0.9333333333333333,\n",
       "  0.6363636363636364,\n",
       "  0.8636363636363636])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCA_Classification(np.array(data), [1,2,3,4,5,6,7,8,9,10,11,12,13], 0)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

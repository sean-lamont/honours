{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CodaPCA\n",
    "import CodaRegressmb as CodaRegress\n",
    "import numpy as np\n",
    "from runpca import read_csv\n",
    "import os\n",
    "import sklearn\n",
    "import torch\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#change module for newer sklearn versions\n",
    "from sklearn.model_selection  import cross_val_score\n",
    "from sklearn.model_selection  import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import PCARegress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the data. Given an array of which files are regression, classification or unlabelled\n",
    "data_path = os.getcwd() + \"/Aitchinson\"\n",
    "\n",
    "regression_list = [3,4,5,18,21,34,39]\n",
    "classification_list = [7,8,9,11,12,16,17,19,23,24,25,26,28,29,33,37]\n",
    "unlabelled_list=[1,2,6,10,13,14,15,20,22,27,30,31,32,35,36,38,40]\n",
    "\n",
    "r_files = []\n",
    "c_files = []\n",
    "u_files = []\n",
    "\n",
    "\n",
    "for file in os.listdir(data_path):\n",
    "    for i in regression_list:\n",
    "        if os.path.isfile(os.path.join(data_path,file)) and 'Data ' + str(i) + '.' in file:\n",
    "            r_files.append(\"Aitchinson/\" + file)\n",
    "    for i in classification_list:\n",
    "        if os.path.isfile(os.path.join(data_path,file)) and 'Data ' + str(i) + '.' in file:\n",
    "            c_files.append(\"Aitchinson/\" + file)\n",
    "    for i in unlabelled_list:\n",
    "        if os.path.isfile(os.path.join(data_path,file)) and 'Data ' + str(i) + '.' in file:\n",
    "            u_files.append(\"Aitchinson/\" + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coda_val(features, targets, n_components, folds):\n",
    "    targets = targets.reshape(-1,1)\n",
    "    param_splits = 2\n",
    "    kfold_scores = []\n",
    "    for train, test in folds:        \n",
    "        Y_train = targets[train]\n",
    "        X_train = features[train]\n",
    "        \n",
    "       \n",
    "        Y_test = targets[test]\n",
    "        X_test = features[test]\n",
    "        \n",
    "        \n",
    "        kf_inner = KFold(param_splits)\n",
    "        \n",
    "        inner_folds = [i for i in kf_inner.split(X_train)]      \n",
    "            \n",
    "        #inner loop for parameter selection (lambda term in combined loss):\n",
    "        param_grid = [1e-15,1e-12,1e-10,0.01]\n",
    "        \n",
    "        max_error = np.inf\n",
    "        for a in param_grid:\n",
    "            \n",
    "            cval_error = []\n",
    "            #find the parameter which obtains the best inner cross val score\n",
    "            for train_inner, test_inner in inner_folds:\n",
    "                \n",
    "                model = CodaRegress.CoDA_Regress(features.shape[1], n_components, [5,], [3,])\n",
    "                \n",
    "                model.fit(torch.FloatTensor(X_train[train_inner]),  torch.FloatTensor(Y_train[train_inner]), a, lr=1e-3,train_size = len(X_train), epochs=1000)\n",
    "\n",
    "                y_inner_pred = model.predict(torch.FloatTensor(X_train[test_inner]))\n",
    "    \n",
    "                cval_error.append(sklearn.metrics.mean_squared_error(Y_train[test_inner],y_inner_pred.detach().numpy()))\n",
    "        \n",
    "        \n",
    "                \n",
    "    \n",
    "   \n",
    "            curr_error = np.mean(cval_error)\n",
    "            if curr_error < max_error:\n",
    "                max_error = curr_error\n",
    "                best_param = a\n",
    "                print (\"Current best\", best_param)\n",
    "        \n",
    "        \n",
    "        best_model = CodaRegress.CoDA_Regress(features.shape[1], n_components, [5,], [3,])\n",
    "\n",
    "        val_arr, train_arr = best_model.fit(torch.FloatTensor(X_train),  torch.FloatTensor(Y_train), best_param, lr=1e-3, train_size = int(len(X_train)*(3/4)), epochs=3000)\n",
    "        \n",
    "        print (\"Plot!\")\n",
    "        \n",
    "        plt.plot(val_arr, c=\"red\")\n",
    "        plt.plot(train_arr, c=\"blue\")\n",
    "        \n",
    "        #plt.ylim(top=-min(train_arr))\n",
    "        plt.ylim(bottom=min(train_arr))\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        y_pred = best_model.predict(torch.FloatTensor(X_test))\n",
    "        kfold_scores.append(sklearn.metrics.mean_squared_error(Y_test,y_pred.detach().numpy()))\n",
    "                \n",
    "    return kfold_scores\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#need to specify where the the targets and features are in the dataset, and whether there are non compositional features\n",
    "\n",
    "def PCA_Regression(data, co_feature_indices, target_index, \n",
    "                   other_feature_indices = [], alg=CodaPCA.Alg.CODAPCA, verbose=True):\n",
    "    \n",
    "    #can loop through/optimise this in another way?\n",
    "    \n",
    "    headers = data[1]\n",
    "    \n",
    "    data = data[0]\n",
    "    np.random.shuffle(data)\n",
    "    features = data[:,co_feature_indices]\n",
    "    targets = data[:,target_index]\n",
    "    \n",
    "    #normalise the compositional features. TODO anything extra to deal with non compositional features?\n",
    "    #features = np.array([feat/sum(feat) for feat in features])\n",
    "\n",
    "    #can be empty\n",
    "    #extra_features = data[0][:,other_feature_indices]\n",
    "    \n",
    "    #TODO double check this\n",
    "    #features = np.hstack([features, extra_features])\n",
    "    \n",
    "    #compute the CoDA-PCA projection \n",
    "    #TODO add component number as a hyperparameter to optimise \n",
    "    n_components=2#len(co_feature_indices)-2\n",
    "\n",
    "    pca = CodaPCA.NonParametricCodaPCA(n_components)#CodaPCA(n_components,lrate=1e-4,nn_shape=[100,100], alg=alg)\n",
    "    #TODO: check why this is numerically unstable\n",
    "    #pca = CodaPCA.NonParametricCodaPCA(n_components)\n",
    "\n",
    "    pca.fit(features)\n",
    "    \n",
    "    Y_coda = pca.transform(features)\n",
    "\n",
    "    pca_clr = CodaPCA.CLRPCA(n_components)\n",
    "    pca_clr.fit(features)\n",
    "    \n",
    "    Y_clr = pca_clr.transform(features)\n",
    "    \n",
    "    pca_reg = CodaPCA.PCA(n_components)\n",
    "    pca_reg.fit(features)\n",
    "    \n",
    "    Y_pca = pca_reg.transform(features)\n",
    "    \n",
    "    splits = 4\n",
    "        \n",
    "    #split data \n",
    "    kf = KFold(splits)\n",
    "        \n",
    "    folds = [i for i in kf.split(features)]      \n",
    "    \n",
    "\n",
    "    lm = Ridge()\n",
    "    \n",
    "    coda_score = enhanced_cross_val(lm,Y_coda, targets, folds)\n",
    "    clr_score = enhanced_cross_val(lm,Y_clr, targets, folds) \n",
    "    naive_score = enhanced_cross_val(lm, Y_pca, targets, folds)\n",
    "    \n",
    "    regress_score = coda_val(features, targets, n_components, folds)\n",
    "    \n",
    "\n",
    "\n",
    "    if verbose:\n",
    "        print(\"CoDA-PCA:\")\n",
    "        print(coda_score)\n",
    "        print(\"CLR-PCA:\")\n",
    "        print(clr_score)\n",
    "        print (\"Naive regression:\")\n",
    "        print (naive_score)\n",
    "        print (\"CoDA-Regress:\")\n",
    "        print (regress_score)\n",
    "    \n",
    "\n",
    "    return coda_score,clr_score,naive_score,regress_score\n",
    "\n",
    "#training methodology as described in:\n",
    "#https://papers.nips.cc/paper/3215-learning-with-transformation-invariant-kernels.pdf\n",
    "def enhanced_cross_val(model, features, targets, folds):\n",
    "    assert len(features) == len(targets), \"Mismatch in length of features and targets\"\n",
    "    \n",
    "    #define the number of splits and folds uised in the parameter selection\n",
    "    #stick to smaller splits since we have small datasets\n",
    "    #splits = 4\n",
    "    param_splits = 3\n",
    "    #split data \n",
    "    #kf = KFold(splits)\n",
    "    kfold_scores = []\n",
    "    \n",
    "    for train, test in folds:        \n",
    "        Y_train = targets[train]\n",
    "        X_train = features[train]\n",
    "        \n",
    "       \n",
    "        Y_test = targets[test]\n",
    "        X_test = features[test]\n",
    "        \n",
    "        #inner loop for parameter selection (regularisation term in Ridge Regression):\n",
    "        param_grid = [0.01,0.05,0.1,0.5,1.0,5.0,10.0,50.0,100.0]\n",
    "        max_score = -np.inf\n",
    "        for a in param_grid:\n",
    "            lm = Ridge(a)\n",
    "   \n",
    "            curr_score = np.mean(cross_val_score(lm, X_train, Y_train,cv=param_splits))\n",
    "            if curr_score > max_score:\n",
    "                max_score = curr_score\n",
    "                best_param = a\n",
    "                \n",
    "        \n",
    "        #compute test score based on best parameter\n",
    "        lm = Ridge(best_param)\n",
    "        lm.fit(X_train, Y_train)\n",
    "        y_pred = lm.predict(X_test)\n",
    "        kfold_scores.append(sklearn.metrics.mean_squared_error(Y_test,y_pred))\n",
    "                \n",
    "    return kfold_scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Aitchinson/Data 18. Compositions and total pebble counts of 92 glacial tills.csv...\n",
      "92 samples 5 features\n",
      "sparsity: 10.434782608695652%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\u5801283\\Documents\\Honours\\honours_final\\honours\\Code\\coda-pca-orig\\coda\\codes\\CodaPCA.py:526: RuntimeWarning: invalid value encountered in subtract\n",
      "  gradU -= gradU.mean( 1, keepdims=True )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current best 1e-15\n",
      "epoch 1000, loss 40630.91796875\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#can automate this if we had assume a certain structure for the indices of features and targets, or an array per dataset \n",
    "%matplotlib inline\n",
    "\n",
    "score_dict = {} \n",
    "\n",
    "#TODO r_files isn't always consistent\n",
    "\n",
    "# data_21_scores = PCA_Regression(read_csv(\"Aitchinson/Data 21. Permeabilities of bayesite for 21 mixtures of fibres and bonding pressures..csv\", normalize=False), co_feature_indices=[0,1,2,3], target_index=4)\n",
    "# score_dict['21'] = data_21_scores\n",
    "\n",
    "# data_21_scores2 = PCA_Regression(read_csv(\"Aitchinson/Data 21. Permeabilities of bayesite for 21 mixtures of fibres and bonding pressures..csv\", normalize=False), co_feature_indices=[0,1,2,3], target_index=5)\n",
    "# score_dict['21,2'] = data_21_scores2\n",
    "\n",
    "# data_34_scores = PCA_Regression(read_csv(\"Aitchinson/Data 34. Foraminiferal compositions at 30 different depths.csv\", normalize=False), co_feature_indices=[0,1,2,3], target_index=4) \n",
    "# score_dict['34'] = data_34_scores\n",
    "\n",
    "# data_3_scores = PCA_Regression(read_csv(\"Aitchinson/Data 3. Compositions and depths of 25 specimens of boxite (Percentages by weight).csv\", normalize=False), co_feature_indices=[0,1,2,3,4], target_index=5) \n",
    "# score_dict['3'] = data_3_scores\n",
    "\n",
    "# data_39_scores = PCA_Regression(read_csv(\"Aitchinson/Data 39. Microhardness of 18 glass specimens and their (Ge, Sb, Se) compositions.csv\", normalize=False), co_feature_indices=[0,1,2], target_index=3)\n",
    "# score_dict['39'] = data_39_scores\n",
    "\n",
    "# data_4_scores = PCA_Regression(read_csv(\"Aitchinson/Data 4. Compositions, depths and porosities of 25 specimens of coxite (Percentages by weight).csv\", normalize=False), co_feature_indices=[0,1,2,3,4], target_index=5)\n",
    "# score_dict['4'] = data_4_scores\n",
    "\n",
    "# data_4_scores2 = PCA_Regression(read_csv(\"Aitchinson/Data 4. Compositions, depths and porosities of 25 specimens of coxite (Percentages by weight).csv\", normalize=False), co_feature_indices=[0,1,2,3,4], target_index=6)\n",
    "# score_dict['4,2'] = data_4_scores2\n",
    "\n",
    "# data_5_scores = PCA_Regression(read_csv(\"Aitchinson/Data 5. Sand, silt, clay compositions of 39 sediment samples at different water depths in an Arctic lake.csv\", normalize=False), co_feature_indices=[0,1,2], target_index=3)\n",
    "# score_dict['5'] = data_5_scores\n",
    "\n",
    "data_18_scores = PCA_Regression(read_csv(\"Aitchinson/Data 18. Compositions and total pebble counts of 92 glacial tills.csv\", normalize=False), co_feature_indices=[0,1,2,3], target_index=4)\n",
    "score_dict['18'] = data_18_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#note: plotly code works fine, but gives a jupyter warning when saving with a rendered table\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "\n",
    "table_rows = []\n",
    "for key in score_dict.keys():\n",
    "    mean_scores = list(map(np.mean, score_dict[key]))\n",
    "    mean_scores = [ '%.2f' % elem for elem in mean_scores ]\n",
    "    table_rows.append([key,*mean_scores])\n",
    "    \n",
    "results = [go.Table(\n",
    "    header=dict(values=[\"\",\"CoDA-PCA\", \"CLR-PCA\", \"Naive Regression\", \"CoDA-Regress\"]),\n",
    "    cells=dict(values=np.array(table_rows).T))]\n",
    "\n",
    "iplot(results, filename = 'basic_table')    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
